# Data-Wrangling-Project--WeRateDogs
## by Ibrahim SHITTU

## Project Overview
> In this project, we used Python and its libraries to gather data from a variety of sources and in a variety of formats, assess its quality and tidiness, then clean it. Technically called the data wrangling process. 

## Dataset Description 
> The project is majorly to conduct wrangling on tweet archive dataset of Twitter user @dog_rates(https://twitter.com/dog_rates), also known as WeRateDogs. This archive/dataset consists of 2356 basic tweet data from November, 2015 to August, 2017. WeRateDogs is a Twitter account that rates people's dogs with a humorous comments.

> Based on the archive dataset (i.e. WeRateDogs Twitter archive), another dataset is created which consists of image predictions alongside each tweet ID, image URL, and the image number that corresponded to the most confident prediction. also, additional live data was accessed via Api using tweet IDs in the twitter archive to generate current learnings from the dataset.

> The project main objectives is as follows: 
> • Perform data wrangling (gathering, assessing and cleaning) on provided the sources of data. 
> • Store, analyze, and visualize the wrangled data. 

## Summary of Wrangling
> The cleaned WeRateDogs Twitter data prepared for analysis has 2077 rows and 13 columns with which interesting analyses and visualizations were created to communicate insights derived therein.

> To ensure engaged attention in the course of insights communication, Python libraries such as matplotlib and seaborn were deployed to generate some catchy visualizations for analysis.
